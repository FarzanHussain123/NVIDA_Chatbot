# üß† NVIDIA Chatbot  

An intelligent **AI chatbot** that uses **FAISS-based retrieval** and **NVIDIA‚Äôs Llama 3.1 Nemotron Nano 8B** model for generating human-like, context-aware responses.  

This project demonstrates how to ingest data, create embeddings, and build an AI assistant capable of answering questions based on your own documents.  

---

## ‚öôÔ∏è Installation & Setup  

Follow these steps to download, configure, and run the chatbot locally:  

```bash
# Step 1Ô∏è‚É£ ‚Äî Clone the repository from GitHub
git clone https://github.com/<your-username>/NVIDIA_Chatbot.git
cd NVIDIA_Chatbot

# Step 2Ô∏è‚É£ ‚Äî Create a Python virtual environment (recommended)
python -m venv venv

# Step 3Ô∏è‚É£ ‚Äî Activate the virtual environment
# ‚ñ∂ On macOS / Linux:
source venv/bin/activate
# ‚ñ∂ On Windows:
venv\Scripts\activate

# Step 4Ô∏è‚É£ ‚Äî Install required dependencies
pip install -r requirements.txt
# Step 5Ô∏è‚É£ ‚Äî Get and configure your NVIDIA API Key

# 1Ô∏è‚É£  Visit the NVIDIA Build Portal:
#     https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1

# 2Ô∏è‚É£  Sign in with your NVIDIA account (create one if needed).

# 3Ô∏è‚É£  Click ‚ÄúGet API Key‚Äù and copy your key.

# 4Ô∏è‚É£  In your project root folder, create a file named `.env`
#     and add the following line inside it:

NVIDIA_API_KEY=your_api_key_here

# Example:
NVIDIA_API_KEY=nvapi_123456789abcdef

# 5Ô∏è‚É£  (Optional) You can also set it manually in your terminal:
# ‚ñ∂ On Windows:
set NVIDIA_API_KEY=your_api_key_here
# ‚ñ∂ On macOS / Linux:
export NVIDIA_API_KEY=your_api_key_here
# Step 6Ô∏è‚É£ ‚Äî Ingest your documents
# This processes files in /docs, chunks text, generates embeddings, and builds a FAISS index.
python ingest.py
# Step 7Ô∏è‚É£ ‚Äî Launch the chatbot agent
# The chatbot uses NVIDIA‚Äôs Llama API with FAISS for retrieval-augmented generation (RAG).
python agent.py
